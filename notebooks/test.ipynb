{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(linewidth=500, edgeitems=20, precision=4, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carca.data import CARCADataset, load_attrs, load_ctx, load_profiles\n",
    "from carca.model import MultiHeadAttention\n",
    "from carca.utils import get_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = load_attrs(\"video_games\")\n",
    "ctx = load_ctx(\"video_games\")\n",
    "user_ids, item_ids, profiles = load_profiles(\"video_games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items = len(item_ids) + 1\n",
    "n_ctx = next(iter(ctx.values())).shape[0]\n",
    "n_attrs = attrs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters for Games dataset\n",
    "learning_rate =  0.0001\n",
    "seq_len = 50\n",
    "n_blocks = 3\n",
    "n_heads = 3\n",
    "dropout_rate = 0.5\n",
    "l2_reg = 0.0\n",
    "d_dim = 90\n",
    "g_dim = 450\n",
    "residual_sa = True\n",
    "residual_ca = True\n",
    "epochs = 800\n",
    "batch_size = 128\n",
    "beta1 = 0.9\n",
    "beta2 = 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CARCADataset(\n",
    "    user_ids=user_ids,\n",
    "    item_ids=item_ids,\n",
    "    profiles=profiles,\n",
    "    attrs=attrs,\n",
    "    ctx=ctx,\n",
    "    profile_seq_len=10,\n",
    "    target_seq_len=100,\n",
    "    mode=\"train\"\n",
    ")\n",
    "val_data = CARCADataset(\n",
    "    user_ids=user_ids,\n",
    "    item_ids=item_ids,\n",
    "    profiles=profiles,\n",
    "    attrs=attrs,\n",
    "    ctx=ctx,\n",
    "    profile_seq_len=10,\n",
    "    target_seq_len=100,\n",
    "    mode=\"val\"\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=2, shuffle=False, num_workers=0)\n",
    "val_loader = DataLoader(val_data, batch_size=2, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dim = 6\n",
    "g_dim = 14\n",
    "n_heads = 2\n",
    "dropout_rate = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_embed = nn.Embedding(num_embeddings=n_items, embedding_dim=d_dim, padding_idx=0)\n",
    "feats_embed = nn.Linear(in_features=n_ctx + n_attrs, out_features=g_dim)\n",
    "joint_embed = nn.Linear(in_features=g_dim + d_dim, out_features=d_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention\n",
    "norm1 = nn.LayerNorm(normalized_shape=d_dim)\n",
    "attention_sa = nn.MultiheadAttention(embed_dim=d_dim, num_heads=n_heads, dropout=dropout_rate, batch_first=True)\n",
    "\n",
    "# FFN\n",
    "norm2 = nn.LayerNorm(normalized_shape=d_dim)\n",
    "ffn_1 = nn.Conv1d(in_channels=d_dim, out_channels=d_dim, kernel_size=1)\n",
    "activation = nn.LeakyReLU()\n",
    "dropout2 = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "ffn_2 = nn.Conv1d(in_channels=d_dim, out_channels=d_dim, kernel_size=1)\n",
    "dropout3 = nn.Dropout(p=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_own = MultiHeadAttention(embed_dim=d_dim, num_heads=n_heads, dropout=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention\n",
    "attention_ca = nn.MultiheadAttention(embed_dim=d_dim, num_heads=n_heads, batch_first=True)\n",
    "\n",
    "# FFN\n",
    "ffn_ca = nn.Conv1d(in_channels=d_dim, out_channels=1, kernel_size=1)\n",
    "sig = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_m = nn.Dropout(p=dropout_rate)\n",
    "norm_m = nn.LayerNorm(normalized_shape=d_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x, p_ac, o_x, o_ac, y_true = next(loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mask, o_mask = get_mask(p_x), get_mask(o_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_z = items_embed.forward(p_x)\n",
    "p_q = feats_embed.forward(p_ac)\n",
    "p_e = joint_embed.forward(torch.cat((p_z, p_q), dim=-1))\n",
    "p_e = p_e * p_mask.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_e = dropout_m.forward(p_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat1, mat2 = p_mask.unsqueeze(1).permute(0, 2, 1).float(), p_mask.unsqueeze(1).float()\n",
    "# sa_mask = torch.bmm(mat1, mat2)\n",
    "# sa_mask = sa_mask == 0.0\n",
    "# sa_mask = torch.where(sa_mask == 0.0, -1e6, 0.0)\n",
    "# sa_mask = torch.repeat_interleave(sa_mask, n_heads, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_mask = p_mask == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1, mat2 = p_mask.unsqueeze(1).permute(0, 2, 1).float(), p_mask.unsqueeze(1).float()\n",
    "attn_mask = torch.bmm(mat1, mat2).bool()\n",
    "# attn_mask = torch.where(attn_mask == 0.0, -1e6, 0.0)\n",
    "attn_mask = torch.tile(attn_mask, (n_heads, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mat1, mat2 = o_mask.unsqueeze(1).permute(0, 2, 1).float(), p_mask.unsqueeze(1).float()\n",
    "#attn_mask = torch.bmm(mat1, mat2).bool()\n",
    "#attn_mask = torch.tile(attn_mask, (n_heads, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_query = norm1.forward(p_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_s = attn_own.forward(p_query, p_e, p_e, attn_mask=attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_s, p_w = attention_sa.forward(p_query, p_e, p_e, key_padding_mask=sa_mask, need_weights=True, average_attn_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_ss = attn_own.forward(p_query, p_e, p_e, attn_mask=attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_s = p_s * p_mask.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_s = torch.mul(p_s, p_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_s = norm2.forward(p_s)\n",
    "p_f = p_s.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_f = ffn_1.forward(p_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_f = activation.forward(p_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_f = dropout2.forward(p_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_f = ffn_2.forward(p_f)\n",
    "p_f = dropout3.forward(p_f)\n",
    "p_f = p_f.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_f = p_f * p_mask.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_z = items_embed.forward(o_x)\n",
    "e_q = feats_embed.forward(o_ac)\n",
    "e_e = joint_embed.forward(torch.cat((e_z, e_q), dim=-1))\n",
    "e_e = e_e * o_mask.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, _ = attention_ca.forward(e_e, p_f, p_f, key_padding_mask=p_mask == 0, need_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s * o_mask.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.mul(s, e_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = s.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_ca = nn.Linear(in_features=d_dim, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20, 6])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ffn_ca.forward(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sig.forward(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-8\n",
    "loss = -(y_true * torch.log(y + eps) + (1.0 - y_true) * torch.log(1.0 - y + eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.sum(loss * o_mask) / torch.sum(o_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_e.retain_grad()\n",
    "p_s.retain_grad()\n",
    "p_f.retain_grad()\n",
    "e_e.retain_grad()\n",
    "s.retain_grad()\n",
    "y.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = torch.concat(torch.split(e_e, d_dim // n_heads, dim=2), dim=0)\n",
    "key = torch.concat(torch.split(p_e, d_dim // n_heads, dim=2), dim=0)\n",
    "value = torch.concat(torch.split(p_e, d_dim // n_heads, dim=2), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1, mat2 = o_mask.unsqueeze(1).permute(0, 2, 1).float(), p_mask.unsqueeze(1).float()\n",
    "attn_mask = torch.bmm(mat1, mat2).bool()\n",
    "attn_mask = torch.tile(attn_mask, (n_heads, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_mask = torch.where(attn_mask, 0.0, -1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_mask = torch.tile(o_mask, (n_heads, 1)).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.bmm(query, key.transpose(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.baddbmm(add_mask, query, key.transpose(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "out /= (d_dim / n_heads) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = softmax.forward(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out * query_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.bmm(out, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.concat(torch.split(out, out.shape[0] // n_heads, dim=0), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 1.7562, -0.9502,  1.8173,  1.1411,  0.9791,  0.5281],\n",
       "        [ 2.7138, -1.2549,  2.7758,  1.4265,  0.9230,  0.4740],\n",
       "        [ 2.9417, -1.3218,  2.9812,  1.6699,  1.3413,  0.5687],\n",
       "        [ 2.1356, -1.0711,  2.1962,  1.2098,  1.0064,  0.5241],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.9659, -0.6873,  0.9925,  0.9614,  0.6571,  0.4517],\n",
       "        [ 1.0312, -0.7073,  1.0510,  1.0904,  0.8710,  0.5004],\n",
       "        [ 2.9140, -1.3139,  2.9569,  1.5836,  1.1787,  0.5291],\n",
       "        [ 1.0747, -0.7257,  1.1135,  1.0497,  0.7755,  0.4770]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1, mat2 = o_mask.unsqueeze(1).permute(0, 2, 1).float(), p_mask.unsqueeze(1).float()\n",
    "attn_mask = torch.bmm(mat1, mat2).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(in_features=10, out_features=1)\n",
    "conv1d = nn.Conv1d(in_channels=10, out_channels=1, kernel_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_t = torch.randn((4, 10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_t = linear.forward(in_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 1])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 10])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d.forward(in_t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.11], requires_grad=True)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(inputs, epsilon=1e-8, scope=\"ln\", reuse=None):\n",
    "    \"\"\"Applies layer normalization.\n",
    "\n",
    "    Args:\n",
    "      inputs: A tensor with 2 or more dimensions, where the first dimension has\n",
    "        `batch_size`.\n",
    "      epsilon: A floating number. A very small number for preventing ZeroDivision Error.\n",
    "      scope: Optional scope for `variable_scope`.\n",
    "      reuse: Boolean, whether to reuse the weights of a previous layer\n",
    "        by the same name.\n",
    "\n",
    "    Returns:\n",
    "      A tensor with the same shape and data dtype as `inputs`.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        inputs_shape = inputs.get_shape()\n",
    "        params_shape = inputs_shape[-1:]\n",
    "\n",
    "        mean, variance = tf.nn.moments(inputs, [-1], keep_dims=True)\n",
    "        beta = tf.Variable(tf.zeros(params_shape))\n",
    "        gamma = tf.Variable(tf.ones(params_shape))\n",
    "        normalized = (inputs - mean) / ((variance + epsilon) ** (0.5))\n",
    "        outputs = gamma * normalized + beta\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn((2, 4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon=1e-8\n",
    "inputs_shape = inputs.shape\n",
    "params_shape = inputs_shape[-1:]\n",
    "\n",
    "var, mean = torch.var_mean(inputs, -1, keepdim=True, unbiased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.zeros(params_shape)\n",
    "gamma = torch.ones(params_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = (inputs - mean) / ((var + epsilon) ** (0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1216,  0.9722,  0.5581, -1.6519],\n",
       "         [-0.1728, -1.0248,  1.6483, -0.4507],\n",
       "         [ 0.4595,  0.2377, -1.6695,  0.9723],\n",
       "         [-1.6212,  0.0283,  0.5703,  1.0226]],\n",
       "\n",
       "        [[ 0.1765, -1.1010,  1.5415, -0.6170],\n",
       "         [-0.1468, -1.4077,  1.4052,  0.1493],\n",
       "         [ 1.5495, -0.9658,  0.2061, -0.7898],\n",
       "         [ 0.6270, -0.2344, -1.5144,  1.1218]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = gamma * normalized + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1216,  0.9722,  0.5581, -1.6519],\n",
       "         [-0.1728, -1.0248,  1.6483, -0.4507],\n",
       "         [ 0.4595,  0.2377, -1.6695,  0.9723],\n",
       "         [-1.6212,  0.0283,  0.5703,  1.0226]],\n",
       "\n",
       "        [[ 0.1765, -1.1010,  1.5415, -0.6170],\n",
       "         [-0.1468, -1.4077,  1.4052,  0.1493],\n",
       "         [ 1.5495, -0.9658,  0.2061, -0.7898],\n",
       "         [ 0.6270, -0.2344, -1.5144,  1.1218]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = torch.nn.LayerNorm(4, elementwise_affine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1216,  0.9722,  0.5581, -1.6519],\n",
       "         [-0.1728, -1.0248,  1.6483, -0.4507],\n",
       "         [ 0.4595,  0.2376, -1.6692,  0.9721],\n",
       "         [-1.6212,  0.0283,  0.5703,  1.0226]],\n",
       "\n",
       "        [[ 0.1765, -1.1009,  1.5414, -0.6170],\n",
       "         [-0.1468, -1.4077,  1.4052,  0.1493],\n",
       "         [ 1.5495, -0.9658,  0.2061, -0.7898],\n",
       "         [ 0.6270, -0.2344, -1.5144,  1.1218]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln.forward(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('papso-replication')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e30f74691219d7aa0a376b512fc75f5f3e4a9e7bbff7ca6d7328ffbf45b45fd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
