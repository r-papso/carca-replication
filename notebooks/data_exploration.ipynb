{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ctx(dataset_name) -> Dict[Tuple[int, int], np.ndarray]:\n",
    "    with open(f\"../data/{dataset_name}_ctx.dat\", \"rb\") as rf:\n",
    "        ctx = pickle.load(rf)\n",
    "    \n",
    "    # Cast context values from list to numpy array\n",
    "    for k in ctx.keys():\n",
    "        ctx[k] = np.array(ctx[k])\n",
    "    \n",
    "    return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attrs(dataset_name) -> np.ndarray:\n",
    "    with open(f\"../data/{dataset_name}_attrs.dat\", \"rb\") as rf:\n",
    "        attrs = pickle.load(rf)\n",
    "    \n",
    "    # Add zero row for <pad> item\n",
    "    attrs = np.concatenate((np.zeros((1, attrs.shape[1])), attrs), axis=0)\n",
    "    return attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_profiles(dataset_name):\n",
    "    user_ids, item_ids = set(), set()\n",
    "    profiles = defaultdict(list)\n",
    "\n",
    "    with open(f\"../data/{dataset_name}.txt\", \"r\") as df:\n",
    "        for line in df:\n",
    "            user_id, item_id = list(map(int, line.strip().split(\" \")))\n",
    "            user_ids.add(user_id)\n",
    "            item_ids.add(item_id)\n",
    "            profiles[user_id].append(item_id)\n",
    "    \n",
    "    return list(user_ids), list(item_ids), profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_out_idx(profile: List[int], mode: str) -> int:\n",
    "    if mode not in [\"train\", \"val\", \"test\"]:\n",
    "        raise ValueError(f\"Invalid mode: {mode}\")\n",
    "    \n",
    "    if mode == \"train\" and len(profile) > 1:\n",
    "        return max(1, len(profile) - 3)\n",
    "    \n",
    "    if mode == \"val\" and len(profile) > 2:\n",
    "        return max(2, len(profile) - 2)\n",
    "    \n",
    "    if mode == \"test\" and len(profile) > 3:\n",
    "        return len(profile) - 1\n",
    "    \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_profile(profile: List[int], max_len: int, mode: str) -> List[int]:\n",
    "    if mode not in [\"train\", \"val\", \"test\"]:\n",
    "        raise ValueError(f\"Invalid mode: {mode}\")\n",
    "\n",
    "    start, end = 0, 0\n",
    "\n",
    "    if mode == \"train\" and len(profile) > 1:\n",
    "        n_excluded = 3\n",
    "        start = max(0, len(profile) - n_excluded - max_len)\n",
    "        end = max(1, len(profile) - n_excluded)\n",
    "\n",
    "    if mode == \"val\" and len(profile) > 2:\n",
    "        n_excluded = 1 if len(profile) == 3 else 2\n",
    "        start = max(0, len(profile) - n_excluded - max_len)\n",
    "        end = max(1, len(profile) - n_excluded)\n",
    "\n",
    "    if mode == \"test\" and len(profile) > 3:\n",
    "        n_excluded = 2\n",
    "        start = max(0, len(profile) - n_excluded - max_len)\n",
    "        end = max(1, len(profile) - n_excluded)\n",
    "\n",
    "    return list(range(start, end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_negatives(profile: List[int], n_items: int, n: int) -> List[int]:\n",
    "    sample = []\n",
    "\n",
    "    while len(sample) < n:\n",
    "        item_id = random.randint(1, n_items - 1)\n",
    "\n",
    "        if item_id not in sample and item_id not in profile:\n",
    "            sample.append(item_id)\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_sequences(\n",
    "        user_id: int,\n",
    "        profile: List[int],\n",
    "        seq_len: int,\n",
    "        attrs: np.ndarray,\n",
    "        ctx: Dict[Tuple[int, int], np.ndarray]\n",
    "    ) -> Tuple[np.ndarray, ...]:\n",
    "    q_len = attrs.shape[1] + next(iter(ctx.values())).shape[0]\n",
    "\n",
    "    p_x = np.zeros(seq_len, dtype=np.int32)\n",
    "    o_x = np.zeros(seq_len * 2, dtype=np.int32)\n",
    "    p_q = np.zeros((seq_len, q_len))\n",
    "    o_q = np.zeros((seq_len * 2, q_len))\n",
    "\n",
    "    padded_idxs = pad_profile(profile, seq_len, \"train\")\n",
    "    neg_sample = sample_negatives(profile, attrs.shape[0], len(padded_idxs))\n",
    "\n",
    "    for i, pi in enumerate(padded_idxs):\n",
    "        shift = seq_len - len(padded_idxs)\n",
    "\n",
    "        p_x[shift + i] = profile[pi]\n",
    "        o_x[shift + i] = profile[pi + 1]\n",
    "        o_x[seq_len + shift + i] = neg_sample[i]\n",
    "\n",
    "        a = attrs[profile[pi]]\n",
    "        c = ctx[(user_id, profile[pi])]\n",
    "        p_q[shift + i] = np.concatenate((a, c))\n",
    "\n",
    "        a = attrs[profile[pi + 1]]\n",
    "        c = ctx[(user_id, profile[pi + 1])]\n",
    "        o_q[shift + i] = np.concatenate((a, c))\n",
    "\n",
    "        a = attrs[neg_sample[i]]\n",
    "        c = ctx[((user_id, profile[pi + 1]))]  # Assign same context to negative sample as to positive sample\n",
    "        o_q[seq_len + shift + i] = np.concatenate((a, c))\n",
    "    \n",
    "    y_true = np.zeros(seq_len * 2, dtype=np.int32)\n",
    "    y_true[np.where(p_x > 0)] = 1\n",
    "    mask = np.zeros(seq_len * 2, dtype=np.int32)\n",
    "    mask[np.where(o_x > 0)] = 1\n",
    "    \n",
    "    return p_x, o_x, p_q, o_q, y_true, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_sequences(\n",
    "        user_id: int,\n",
    "        profile: List[int],\n",
    "        profile_seq_len: int,\n",
    "        target_seq_len: int,\n",
    "        attrs: np.ndarray,\n",
    "        ctx: Dict[Tuple[int, int], np.ndarray],\n",
    "        mode: str\n",
    "    ) -> Tuple[np.ndarray, ...]:\n",
    "    q_len = attrs.shape[1] + next(iter(ctx.values())).shape[0]\n",
    "\n",
    "    p_x = np.zeros(profile_seq_len, dtype=np.int32)\n",
    "    o_x = np.zeros(target_seq_len + 1, dtype=np.int32)\n",
    "    p_q = np.zeros((profile_seq_len, q_len))\n",
    "    o_q = np.zeros((target_seq_len + 1, q_len))\n",
    "\n",
    "    one_out = one_out_idx(profile, mode)\n",
    "    a = attrs[profile[one_out]]\n",
    "    c = ctx[(user_id, profile[one_out])]\n",
    "    o_x[0] = profile[one_out]\n",
    "    o_q[0] = np.concatenate((a, c))\n",
    "\n",
    "    padded_idxs = pad_profile(profile, profile_seq_len, mode)\n",
    "    neg_samples = sample_negatives(profile, attrs.shape[0], target_seq_len)\n",
    "\n",
    "    for i, pi in enumerate(padded_idxs):\n",
    "        shift = profile_seq_len - len(padded_idxs)\n",
    "\n",
    "        a = attrs[profile[pi]]\n",
    "        c = ctx[(user_id, profile[pi])]\n",
    "        p_x[shift + i] = profile[pi]\n",
    "        p_q[shift + i] = np.concatenate((a, c))\n",
    "    \n",
    "    for i, oi in enumerate(neg_samples, start=1):\n",
    "        a = attrs[oi]\n",
    "        c = ctx[(user_id, profile[one_out])]  # Assign same context to negatives as to one-out positive\n",
    "        o_x[i] = oi\n",
    "        o_q[i] = np.concatenate((a, c))\n",
    "    \n",
    "    y_true = np.zeros(target_seq_len + 1, dtype=np.int32)\n",
    "    y_true[0] = 1\n",
    "    mask = np.ones(target_seq_len + 1, dtype=np.int32)\n",
    "    \n",
    "    return p_x, o_x, p_q, o_q, y_true, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences(\n",
    "    user_id: int,\n",
    "    profile: List[int],\n",
    "    profile_seq_len: int,\n",
    "    target_seq_len: int,\n",
    "    attrs: np.ndarray,\n",
    "    ctx: Dict[Tuple[int, int], np.ndarray],\n",
    "    mode: str\n",
    ") -> Tuple[np.ndarray, ...]:\n",
    "    if mode == \"train\":\n",
    "        return get_train_sequences(user_id, profile, profile_seq_len, attrs, ctx)\n",
    "    else:\n",
    "        return get_test_sequences(user_id, profile, profile_seq_len, target_seq_len, attrs, ctx, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CARCADataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        user_ids: List[int],\n",
    "        item_ids: List[int],\n",
    "        profiles: Dict[int, List[int]],\n",
    "        attrs: np.ndarray,\n",
    "        ctx: Dict[Tuple[int, int], np.ndarray],\n",
    "        profile_seq_len: int,\n",
    "        target_seq_len: int,\n",
    "        mode: str\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_ids = self.valid_user_ids(profiles, mode)\n",
    "        self.item_ids = item_ids\n",
    "        self.profiles = profiles\n",
    "        self.attrs = attrs\n",
    "        self.ctx = ctx\n",
    "        self.profile_seq_len = profile_seq_len\n",
    "        self.target_seq_len = target_seq_len\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.user_ids)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[np.ndarray, ...]:\n",
    "        user_id = self.user_ids[idx]\n",
    "        profile = self.profiles[user_id]\n",
    "\n",
    "        return get_sequences(\n",
    "            user_id,\n",
    "            profile,\n",
    "            self.profile_seq_len,\n",
    "            self.target_seq_len,\n",
    "            self.attrs,\n",
    "            self.ctx,\n",
    "            self.mode\n",
    "        )\n",
    "    \n",
    "    def valid_user_ids(self, profiles: Dict[int, List[int]], mode: str) -> List[int]:\n",
    "        return [uid for uid, profile in profiles.items() if one_out_idx(profile, mode) != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = load_attrs(\"video_games\")\n",
    "ctx = load_ctx(\"video_games\")\n",
    "user_ids, item_ids, profiles = load_profiles(\"video_games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = \"video_games\"\n",
    "records = []\n",
    "\n",
    "with open(f\"../data/{ds_name}_ts.txt\", \"r\") as df:\n",
    "    for line in df:\n",
    "        vals = tuple(map(int, line.strip().split(\" \")))\n",
    "        records.append(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_sorted = sorted(records, key=lambda tup: tup[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/{ds_name}_sorted.txt\", \"w\") as f:\n",
    "    for i, record in enumerate(records_sorted):\n",
    "        line = \" \".join(str(val) for val in record[:2])\n",
    "        line = line + \"\\n\" if i < len(records_sorted) -1 else line\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand((4, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.zeros((4, 10), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true[:, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4116, 0.5234, 0.5795, 0.5253, 0.3428, 0.1094, 0.3882, 0.4722, 0.2408, 0.7886],\n",
       "        [0.1430, 0.1733, 0.9766, 0.0278, 0.3238, 0.8045, 0.5246, 0.5584, 0.6109, 0.4927],\n",
       "        [0.7522, 0.5516, 0.9690, 0.3029, 0.2106, 0.6066, 0.9199, 0.3489, 0.9856, 0.2810],\n",
       "        [0.8397, 0.9874, 0.0470, 0.1061, 0.7803, 0.7747, 0.8167, 0.2351, 0.7567, 0.9092]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted, idxs = torch.sort(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1094, 0.2408, 0.3428, 0.3882, 0.4116, 0.4722, 0.5234, 0.5253, 0.5795, 0.7886],\n",
       "        [0.0278, 0.1430, 0.1733, 0.3238, 0.4927, 0.5246, 0.5584, 0.6109, 0.8045, 0.9766],\n",
       "        [0.2106, 0.2810, 0.3029, 0.3489, 0.5516, 0.6066, 0.7522, 0.9199, 0.9690, 0.9856],\n",
       "        [0.0470, 0.1061, 0.2351, 0.7567, 0.7747, 0.7803, 0.8167, 0.8397, 0.9092, 0.9874]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_sorted = torch.zeros((4, 10), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_sorted[:, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 8, 4, 6, 0, 7, 1, 3, 2, 9],\n",
       "        [3, 0, 1, 4, 9, 6, 7, 8, 5, 2],\n",
       "        [4, 9, 3, 7, 1, 5, 0, 6, 2, 8],\n",
       "        [2, 3, 7, 8, 5, 4, 6, 0, 9, 1]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_sort = torch.gather(y_true, -1, idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = y_true_sort[:, :k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranks = torch.nonzero(top_k)[:, 1]\n",
    "ranks = torch.nonzero(torch.zeros((4, 5), dtype=torch.int32))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], dtype=torch.int64)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = 1 / torch.log2(ranks + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.sum(scores) / top_k.shape[0]).item()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59d02302364d92722781df083a4418cc03ba7c19172f04d4c159339a6c8436ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('replication_study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
